{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Libraries installation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsogIYe7GH1f"
      },
      "outputs": [],
      "source": [
        "%pip install gymnasium[classic-control]\n",
        "%pip install tensorflow\n",
        "%pip install matplotlib\n",
        "%pip install tqdm\n",
        "\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from gymnasium import wrappers\n",
        "from collections import deque\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BWXo2-bMGH1h"
      },
      "outputs": [],
      "source": [
        "class RLAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        learning_rate: float = 0.1,\n",
        "        initial_epsilon: float = 0.5,\n",
        "        epsilon_decay: float = 0.00002,\n",
        "        final_epsilon: float = 0.1,\n",
        "        action_space: int = 3,\n",
        "        discount_factor: float = 0.95,\n",
        "        env: gym.Env = None,\n",
        "        env_size: int = 100,\n",
        "        \n",
        "    ):\n",
        "        \"\"\"Initialize a Reinforcement Learning agent with an empty dictionary\n",
        "        of state-action values (q_values), a learning rate and an epsilon.\n",
        "\n",
        "        Args:\n",
        "            learning_rate: The learning rate\n",
        "            initial_epsilon: The initial epsilon value\n",
        "            epsilon_decay: The decay for epsilon\n",
        "            final_epsilon: The final epsilon value\n",
        "            action_space: The number of action for the environment\n",
        "            discount_factor: The discount factor for computing the Q-value\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.actions = action_space\n",
        "        self.lr = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon = initial_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.final_epsilon = final_epsilon\n",
        "        self.training_error = []\n",
        "        self.discrete_size = [env_size] * len(env.observation_space.high)\n",
        "        self.discrete_win_size = (env.observation_space.high - env.observation_space.low) / self.discrete_size\n",
        "        self.q_values = np.random.uniform(low=-2, high=0, size=(self.discrete_size + [env.action_space.n])) \n",
        "\n",
        "    def policy(self,state) -> int:\n",
        "        state = self.get_discrete_state(state)\n",
        "        return int(np.argmax(self.q_values[state]))\n",
        "    \n",
        "\n",
        "    def get_action(self, obs: np.ndarray) -> int:\n",
        "        \"\"\"\n",
        "        Returns the best action with probability (1 - epsilon)\n",
        "        otherwise a random action with probability epsilon to ensure exploration.\n",
        "        \"\"\"\n",
        "        greedy = random.random() > self.epsilon\n",
        "\n",
        "        # exploitation\n",
        "        if greedy:\n",
        "            # use the train net to get the action value given a state\n",
        "            return self.policy(obs)\n",
        "\n",
        "        # exploration\n",
        "        else:\n",
        "             return np.random.choice(self.actions)\n",
        "\n",
        "\n",
        "    def get_discrete_state(self,state):\n",
        "        \"\"\"\n",
        "        Return a discrete representation of the state, this simplify the learning process\n",
        "        by reducing the complexity of the state and allow fixed size q-table\n",
        "        \"\"\"\n",
        "        discrete_state = (state - self.env.observation_space.low) / self.discrete_win_size\n",
        "        return tuple(discrete_state.astype(np.int))\n",
        "\n",
        "\n",
        "    def save_qtable(\n",
        "        self,\n",
        "        model_name: str,\n",
        "        episode: int,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Saving Q-Tables\n",
        "        \"\"\"\n",
        "        np.save(f'./q_tables/{model_name}/{episode}-qtable.npy', self.q_values)\n",
        "\n",
        "    def load_qtable(\n",
        "        self,\n",
        "        model_name: str,\n",
        "        episode: str\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Load Q-Table\n",
        "        \"\"\"\n",
        "\n",
        "        self.q_values = np.load(f'./q_tables/{model_name}/{episode}-qtable.npy')\n",
        "        \n",
        "\n",
        "    def update(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        action: int,\n",
        "        reward: float,\n",
        "        terminated: bool,\n",
        "        next_obs: np.ndarray,\n",
        "    ):\n",
        "        \"\"\"Updates the Q-value of an action.\"\"\"\n",
        "\n",
        "        # convert np.ndarray to hashable object\n",
        "        obs = self.get_discrete_state(obs)\n",
        "        next_obs = self.get_discrete_state(next_obs)\n",
        "\n",
        "\n",
        "        # get the future q_value for the current observation\n",
        "        future_q_value = (not terminated) * np.max(self.q_values[next_obs])\n",
        "\n",
        "        # get the difference between current q_value and next observation\n",
        "        temporal_difference = (\n",
        "            reward + self.discount_factor * future_q_value - self.q_values[obs + (action,)]\n",
        "        )\n",
        "\n",
        "        # update the q values for the current obseervation and action\n",
        "        self.q_values[obs + (action,)] = (\n",
        "            self.q_values[obs + (action,)] + self.lr * temporal_difference\n",
        "        )\n",
        "\n",
        "        # store the training error, the goal is to reduce it\n",
        "        self.training_error.append(temporal_difference)\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        \"\"\" Decay epsilon value by a constant\"\"\"\n",
        "        self.epsilon = max(self.final_epsilon, self.epsilon - self.epsilon_decay)\n",
        "\n",
        "    def plot_stats(self,env):\n",
        "        rolling_length = 500\n",
        "        fig, axs = plt.subplots(ncols=2, figsize=(12, 5))\n",
        "        axs[0].set_title(\"Episode rewards\")\n",
        "        # compute and assign a rolling average of the data to provide a smoother graph\n",
        "        reward_moving_average = (\n",
        "            np.convolve(\n",
        "                np.array(env.return_queue).flatten(), np.ones(rolling_length), mode=\"valid\"\n",
        "            )\n",
        "            / rolling_length\n",
        "        )\n",
        "        axs[0].plot(range(len(reward_moving_average)), reward_moving_average)\n",
        "        \n",
        "        axs[1].set_title(\"Training Error\")\n",
        "        training_error_moving_average = (\n",
        "            np.convolve(np.array(self.training_error), np.ones(rolling_length), mode=\"same\")\n",
        "            / rolling_length\n",
        "        )\n",
        "        axs[1].plot(range(len(training_error_moving_average)), training_error_moving_average)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_policy(self,actions):\n",
        "        temp_action_x = list(actions.keys())\n",
        "\n",
        "        action_labels = {0: \"left\", 1: \"stay\", 2: \"right\"}\n",
        "        action_x = [action_labels[a] for a in temp_action_x]\n",
        "        action_y = list(actions.values())\n",
        "\n",
        "        colors = ['blue', 'green', 'orange']\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.bar(action_x, action_y, color=colors)\n",
        "        ax.set_ylabel('Ocurrences')\n",
        "        ax.set_title('Actions')\n",
        "        ax.legend(title='Actions policy')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XAa_nklFzZf4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def initialize_directories(model_name):\n",
        "    \"\"\"\n",
        "    Creates new directory in ./q_tables/\n",
        "    \"\"\"\n",
        "    # create model directory for storing models\n",
        "    if not os.path.exists(\"q_tables/\"):\n",
        "        os.makedirs(\"q_tables/\")\n",
        "    \n",
        "    if not os.path.exists(f'./q_tables/{model_name}'):\n",
        "        os.mkdir(f'./q_tables/{model_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 1910/2000 [00:12<00:00, 168.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1880/2000\n",
            "1900/2000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 1943/2000 [00:12<00:00, 154.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1920/2000\n",
            "1940/2000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1996/2000 [00:12<00:00, 135.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1960/2000\n",
            "1980/2000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:12<00:00, 156.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average reward: -120.7965, Accuracy 1.00000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def training_result(model_name, episode):\n",
        "\n",
        "  env = gym.make('MountainCar-v0')\n",
        "\n",
        "  total_reward = 0.0\n",
        "  win = 0\n",
        "  episodes = 2000\n",
        "  actions = {0:0,\n",
        "             1:0,\n",
        "             2:0}\n",
        "\n",
        "  agent = RLAgent(env=env)\n",
        "  agent.load_qtable(model_name, episode)\n",
        "  \n",
        "\n",
        "  for i in tqdm(range(episodes)): # Play 10 episode and take the average\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    truncated = False\n",
        "    episode_reward = 0.0\n",
        "    while not (done or truncated):\n",
        "      action = agent.policy(state)\n",
        "\n",
        "      next_state, reward, done,truncated, info = env.step(action)\n",
        "\n",
        "      # increment action\n",
        "      actions[action] += 1\n",
        "\n",
        "      # Count number of win\n",
        "      if next_state[0] >= 0.5:\n",
        "        win += 1\n",
        "\n",
        "      episode_reward += reward\n",
        "      state = next_state\n",
        "\n",
        "    if i % 20 == 0:\n",
        "        print(f\"{i}/{episodes}\")\n",
        "        \n",
        "    total_reward += episode_reward\n",
        "\n",
        "  average_reward = total_reward / episodes\n",
        "  accuracy = win / episodes\n",
        "\n",
        "  print(f\"Average reward: {average_reward}, Accuracy {accuracy:.5f}\")\n",
        "  agent.plot_policy(actions)\n",
        "\n",
        "model_name = f'LR: 0.1 - DISCOUNT: 0.95 -' \\\n",
        "             f' EPISODES: 90000'\\\n",
        "             f' EPSILON: 0.5'\\\n",
        "             f' TABLE_SIZE: 100'  \n",
        "\n",
        "episode = \"90000\"\n",
        "\n",
        "training_result(model_name,episode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5Rm1R9lGH1j"
      },
      "outputs": [],
      "source": [
        "EPISODES = 90_000             # number of episode to play\n",
        "UPGRADE_STEP =10_000            # frequency of target network upgrade\n",
        "GAMMA = 0.95                  # discount factor\n",
        "LR = 0.1                      # q-table learning rate\n",
        "EPS_MAX = 0.5               # Initial exploration probability\n",
        "EPS_MIN = 0.1           # Final exploration probability\n",
        "DECAY = EPS_MAX / (EPISODES - 1)\n",
        "TABLE_SIZE = 25     # used to compute the size of the q table\n",
        "\n",
        "reward_sum = 0\n",
        "win = 0\n",
        "scores = list()\n",
        "\n",
        "model_name = f'LR: {LR} - DISCOUNT: {GAMMA} -' \\\n",
        "             f' EPISODES: {EPISODES}'\\\n",
        "             f' EPSILON: {EPS_MAX}'\\\n",
        "             f' TABLE_SIZE: {TABLE_SIZE}'\n",
        "\n",
        "initialize_directories(model_name)\n",
        "\n",
        "\n",
        "env = gym.make('MountainCar-v0')\n",
        "agent = RLAgent(\n",
        "    learning_rate=LR,\n",
        "    initial_epsilon=EPS_MAX,\n",
        "    epsilon_decay=DECAY,\n",
        "    final_epsilon=EPS_MIN,\n",
        "    action_space=env.action_space.n,\n",
        "    discount_factor=GAMMA,\n",
        "    env=env,\n",
        "    env_size=TABLE_SIZE,\n",
        ")\n",
        "\n",
        "reward_sum = 0\n",
        "time_scores = deque(maxlen=100)\n",
        "\n",
        "\n",
        "env = wrappers.RecordEpisodeStatistics(env, deque_size=EPISODES)\n",
        "for episode in range(1,EPISODES + 1):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "\n",
        "    step = 1\n",
        "    # play one episode\n",
        "    while not done:\n",
        "\n",
        "        # get an action according to epsilon greedy policy\n",
        "        action = agent.get_action(obs)\n",
        "\n",
        "        # execute the action\n",
        "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "\n",
        "        # update the agent\n",
        "        agent.update(obs, action, reward, terminated, next_obs)\n",
        "\n",
        "        # update if the environment is done and the current obs\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # upgrade to next obs\n",
        "        obs = next_obs\n",
        "\n",
        "        if done:\n",
        "\n",
        "            # store current time for that episode\n",
        "            time_scores.append(step)\n",
        "\n",
        "            # compute avg score\n",
        "            scores_avg = np.mean(time_scores) * -1\n",
        "\n",
        "            if episode % 500 == 0:\n",
        "                print(f\"Episode {episode}/{EPISODES}, e {agent.epsilon:.6f}, avg reward {scores_avg:.2f}, state {next_obs}, time {step}\")\n",
        "                \n",
        "            break\n",
        "\n",
        "        # increment step\n",
        "        step+=1\n",
        "\n",
        "    # Save progress every UPGRADE STEP\n",
        "    if episode % UPGRADE_STEP == 0:\n",
        "        agent.save_qtable(model_name,episode)\n",
        "\n",
        "    agent.decay_epsilon()\n",
        "\n",
        "# plot stats\n",
        "agent.plot_stats(env)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
